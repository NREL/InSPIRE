{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dc32e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bifacialvf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7b1c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 files in the directory\n",
      "47 groundscan files in the directory\n"
     ]
    }
   ],
   "source": [
    "filestarter = \"irr_1axis_2023-09-16_\" # The string your results file names start with.\n",
    "filelist = sorted(os.listdir(os.path.join(testfolder, 'results')))\n",
    "prefixed = [filename for filename in filelist if filename.startswith(filestarter)]\n",
    "# print(prefixed)\n",
    "distance = []\n",
    "groundirrad = []\n",
    "filenamed = []\n",
    "faillist = []\n",
    "Datetime = []\n",
    "Ap_1 = []\n",
    "Ap_2 = []\n",
    "Ap_3 = []\n",
    "Ap_4 = []\n",
    "Ap_5 = []\n",
    "\n",
    "print('{} files in the directory'.format(filelist.__len__()))\n",
    "print('{} groundscan files in the directory'.format(prefixed.__len__()))\n",
    "i = 0  # counter to track # files loaded.\n",
    "\n",
    "for i in range (0, len(prefixed)):\n",
    "    ind = prefixed[i].split('_')\n",
    "\n",
    "    try:\n",
    "        Datetime.append(re.search(\"([0-9]{4}\\-[0-9]{2}\\-[0-9]{2}\\_[0-9]{4})\", prefixed[i])[0])\n",
    "        resultsDF = br.load.read1Result(os.path.join(testfolder, 'results', prefixed[i]))\n",
    "        Ap_1.append(resultsDF['Wm2Back'][0])\n",
    "        Ap_2.append(resultsDF['Wm2Back'][1])\n",
    "        Ap_3.append(resultsDF['Wm2Back'][2])\n",
    "        Ap_4.append(resultsDF['Wm2Back'][3])\n",
    "        Ap_5.append(resultsDF['Wm2Back'][4])\n",
    "\n",
    "        filenamed.append(prefixed[i])\n",
    "    except:\n",
    "        print(\" FAILED \", i, prefixed[i])\n",
    "        faillist.append(prefixed[i])\n",
    "        \n",
    "\n",
    "resultsdf = pd.DataFrame(list(zip(Ap_1, Ap_2, Ap_3, Ap_4, Ap_5)), columns = ['Ap_1', 'Ap_2', 'Ap_3', 'Ap_4', 'Ap_5'])\n",
    "\n",
    "resultsdf['Datetime'] = Datetime\n",
    "resultsdf['Datetime'] = pd.to_datetime(resultsdf['Datetime'], format ='%Y-%m-%d_%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc588988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Datetime location  index         ghi         par\n",
      "0  2023-09-16 06:00:00       pv      0   38.265983   91.092239\n",
      "1  2023-09-16 06:15:00       pv      1   30.877190   99.422738\n",
      "2  2023-09-16 06:30:00       pv      2   22.926993   82.363319\n",
      "3  2023-09-16 06:45:00       pv      3   80.726105  210.091831\n",
      "4  2023-09-16 07:00:00       pv      4   55.949033  153.040217\n",
      "..                 ...      ...    ...         ...         ...\n",
      "89 2023-09-16 16:30:00      con     42  303.666933  563.465340\n",
      "90 2023-09-16 16:45:00      con     43  250.607267  455.401733\n",
      "91 2023-09-16 17:00:00      con     44  198.799933  344.581373\n",
      "92 2023-09-16 17:15:00      con     45  148.739067  162.476525\n",
      "93 2023-09-16 17:30:00      con     46  100.886640   73.462101\n",
      "\n",
      "[94 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Index the modeled data to the datetime column and add suffix before concatenating with the measured data. This will allow the \"inner\" join of the two dataframes using the indexed datetime and easy pivoting of the data afterwards.\n",
    "modeled = resultsdf.set_index('Datetime')\n",
    "modeled_suffix = modeled.add_suffix(\".modeled\")\n",
    "modeled['datatype']=\"modeled\"\n",
    "\n",
    "# Load the measured data\n",
    "measured = pd.read_csv(os.path.join(os.path.join(Path().resolve(), 'Data','BARNirrad_measured.csv')), header = 1) # The field pyranometer data\n",
    "srrl_weather = pd.read_csv(str(Path().resolve() / 'WeatherFiles' /  'PSM3_15T.csv'), header = 2) # Data from SRRL\n",
    "\n",
    "# Create a Datetime variable and set it as the index\n",
    "srrl_weather['date'] = srrl_weather[['Year','Month','Day']].astype(str).agg('-'.join, axis=1) # Couldn't think of a proper way to chain this process into a single command. If you think of something, please let me know\n",
    "srrl_weather['time'] = srrl_weather[['Hour','Minute']].astype(str).agg(':'.join, axis=1)\n",
    "srrl_weather['Datetime'] = pd.to_datetime(srrl_weather[['date','time']].agg(\" \".join, axis=1))\n",
    "srrl_weather.set_index('Datetime', inplace=True)\n",
    "\n",
    "# Create a Datetime variable for the measured data using the existing 'TIMESTAMP' column.\n",
    "measured['Datetime'] = pd.to_datetime(measured['TIMESTAMP'], format ='%m/%d/%Y %H:%M')\n",
    "measured = measured.drop([\"TIMESTAMP\", \"RECORD\"], axis = 'columns') # drop this column so the resample command does not confuse TIMESTAMP and Datetime columns\n",
    "measured = measured.set_index('Datetime').resample('15T', axis = 'index', label='left', closed='right').mean() # The \"label\" and the \"closed\" arguments are different from that of how the SRRL data was read-in (which was \"right\" for both arguments), but this somehow yields a better timing match.\n",
    "\n",
    "# Add suffix to the columns in the measured dataframe before concatenating it with the modeled dataframe\n",
    "measured_suffix = measured.add_suffix(\".measured\")\n",
    "measured[\"datatype\"]=\"measured\"\n",
    "\n",
    "modeledandmeasured_suffix = pd.concat([modeled_suffix, measured_suffix], axis=1, join='inner')\n",
    "modeledandmeasured_melt = pd.wide_to_long(df = modeledandmeasured_suffix.reset_index(), stubnames= [\"Ap_1\", \"Ap_2\", \"Ap_3\", \"Ap_4\", \"Ap_5\",\"ST_con\", \"ST_pv_bp\", \"ST_pv_is\", \"PAR_con\", \"PAR_pv\", \"Batt_Volt\", \"PTemp_C\"], i = \"Datetime\", j = \"datatype\", sep = \".\", suffix = \"\\D+\").reset_index().set_index('Datetime')\n",
    "\n",
    "modeledandmeasured_melt2 = modeledandmeasured_melt[['datatype', 'Ap_1', 'Ap_2', 'Ap_3', 'Ap_4', 'Ap_5']].reset_index().melt(id_vars = ['Datetime', 'datatype'], var_name = 'position', value_name= 'value').reset_index()\n",
    "modeledandmeasured_melt3 = modeledandmeasured_melt2.pivot(index=['Datetime', 'position'], columns = 'datatype', values = 'value')\n",
    "\n",
    "\n",
    "# Sum up the irradiance values and divide it by 4 to get accumulated daily radiation\n",
    "modeledandmeasured_sum = modeledandmeasured_melt2.reset_index().groupby(['position', 'datatype']).agg({\"value\":\"sum\"})['value'].transform(lambda x:x/4)\n",
    "\n",
    "# Grab just the measured\n",
    "ghipar = modeledandmeasured_melt.loc[modeledandmeasured_melt['datatype']=='measured'][['Ap_3', 'PAR_pv', 'PAR_con']]\n",
    "srrlandghipar = pd.concat([ghipar, srrl_weather], axis=1, join=\"inner\")[['Ap_3','GHI', 'PAR_pv', 'PAR_con']].rename(columns={'Ap_3':'ghi_pv','GHI':'ghi_con','PAR_pv':'par_pv','PAR_con':'par_con'}).reset_index()\n",
    "srrlandghipar = pd.wide_to_long(df = srrlandghipar.reset_index(), stubnames=['ghi','par'], i = \"Datetime\", j = \"location\", sep = \"_\", suffix = \"\\D+\").reset_index()\n",
    "print(srrlandghipar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30010022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tidy the data\n",
    "# modeled_melt = resultsdf.melt(id_vars = ['Datetime'], var_name = 'position', value_name = 'value')\n",
    "# modeled_melt['datatype'] = 'modeled'\n",
    "\n",
    "# # Load the measured data\n",
    "# measured = pd.read_csv(os.path.join(os.path.join(Path().resolve(), 'Data','BARNirrad_measured.csv')), header = 1)\n",
    "# # print(resultsdf_melt.info)\n",
    "# # measured.info\n",
    "\n",
    "# measured['Datetime'] = pd.to_datetime(measured['TIMESTAMP'], format ='%m/%d/%Y %H:%M')\n",
    "# measured = measured.drop(['TIMESTAMP'], axis='columns').set_index('Datetime')\n",
    "# measured_15Tmean = measured.resample('15T', axis = 'index', label='right', closed='right').mean()\n",
    "# # measured_select = measured[['Datetime', 'Ap_1', 'Ap_2', 'Ap_3', 'Ap_4', 'Ap_5']]\n",
    "# measured_melt = measured.reset_index()[['Datetime', 'Ap_1', 'Ap_2', 'Ap_3', 'Ap_4', 'Ap_5']].melt(\n",
    "#     id_vars = ['Datetime'],\n",
    "#     var_name = 'position', \n",
    "#     value_name = 'value')\n",
    "# measured_melt['datatype'] = 'measured'\n",
    "\n",
    "# # combined = pd.merge(resultsdf_melt, measured_melt, how = 'left', on = 'Datetime')\n",
    "# measured_melt = pd.merge(modeled_melt[['Datetime']], measured_melt, how = 'left', on = 'Datetime')\n",
    "# measured_melt.drop_duplicates(inplace=True)\n",
    "# combined = pd.concat([modeled_melt, measured_melt])\n",
    "\n",
    "\n",
    "# # Make wider for another plot\n",
    "# # combined_wider = combined.pivot(index=['Datetime', 'position'], columns='datatype', values = 'value').reset_index().set_index('Datetime')\n",
    "# combined_wider = combined.pivot(index=['Datetime', 'position'], columns='datatype', values = 'value').reset_index()\n",
    "# # print(combined_wider)\n",
    "# combined_wider['time'] = pd.to_datetime(combined_wider['Datetime'], format = '%H:%M')\n",
    "# combined_wider = combined_wider.set_index(\"Datetime\")\n",
    "# # Sum up the irradiance values\n",
    "# # combined_sum = combined.groupby(['position', 'datatype']).agg(np.sum())\n",
    "# combined['totalrad'] = combined.groupby(['position', 'datatype'])['value'].transform(lambda x: x.sum() / 4)\n",
    "# combined_summary = combined[['position','datatype','totalrad']].drop_duplicates()\n",
    "# print(combined_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea7a18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at residuals (MBD, RMSE) based on Grear, Gpoa and Gtotal_modeled. From B. Marion Solar Energy 2016\n",
    "def MBD(meas,model):\n",
    "    # MBD=100∙[((1⁄(m)∙∑〖(y_i-x_i)]÷[(1⁄(m)∙∑〖x_i]〗)〗)\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'model':model,'meas':meas})\n",
    "    # rudimentary filtering of modeled irradiance\n",
    "    df = df.dropna()\n",
    "    minirr = meas.min()\n",
    "    df = df[df.model>minirr]\n",
    "    m = df.__len__()\n",
    "    out = 100*((1/m)*sum(df.model-df.meas))/df.meas.mean()\n",
    "    return out\n",
    "\n",
    "def RMSE(meas,model):\n",
    "    #RMSD=100∙〖[(1⁄(m)∙∑▒(y_i-x_i )^2 )]〗^(1⁄2)÷[(1⁄(m)∙∑▒〖x_i]〗)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'model':model,'meas':meas})\n",
    "    df = df.dropna()\n",
    "    minirr = meas.min()\n",
    "    df = df[df.model>minirr]\n",
    "    m = df.__len__()\n",
    "    out = 100*np.sqrt(1/m*sum((df.model-df.meas)**2))/df.meas.mean()\n",
    "    return out\n",
    "\n",
    "# residuals absolute output (not %) \n",
    "def MBD_abs(meas,model):\n",
    "    # MBD=100∙[((1⁄(m)∙∑〖(y_i-x_i)]÷[(1⁄(m)∙∑〖x_i]〗)〗)\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'model':model,'meas':meas})\n",
    "    # rudimentary filtering of modeled irradiance\n",
    "    df = df.dropna()\n",
    "    minirr = meas.min()\n",
    "    df = df[df.model>minirr]\n",
    "    m = df.__len__()\n",
    "    out = ((1/m)*sum(df.model-df.meas))\n",
    "    return out\n",
    "\n",
    "def RMSE_abs(meas,model):\n",
    "    #RMSD=100∙〖[(1⁄(m)∙∑▒(y_i-x_i )^2 )]〗^(1⁄2)÷[(1⁄(m)∙∑▒〖x_i]〗)\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({'model':model,'meas':meas})\n",
    "    df = df.dropna()\n",
    "    minirr = meas.min()\n",
    "    df = df[df.model>minirr]\n",
    "    m = df.__len__()\n",
    "    out = np.sqrt(1/m*sum((df.model-df.meas)**2))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a381d1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the empty arrays (or lists? I don't know all the object types in python) to save the result of the looped error analysis\n",
    "MBD_result = []\n",
    "RMSE_result = []\n",
    "MBD_abs_result = []\n",
    "RMSE_abs_result = []\n",
    "faillist = []\n",
    "\n",
    "# Grab the list of column names\n",
    "colnames = list(modeledandmeasured_suffix.columns.values)\n",
    "modposition = []\n",
    "measposition = []\n",
    "\n",
    "# Setting the index to 0 prior to running the for-loop\n",
    "i = 0\n",
    "\n",
    "# For-looping the error analyses\n",
    "for i in range (0, 5): # The index range was determined after looking at the \n",
    "    try:\n",
    "        MBD_result.append(MBD(modeledandmeasured_suffix[colnames[i+5]], modeledandmeasured_suffix[colnames[i]])) # The modeled columns and the measured counterparts are five columns apart, hence \"i\" and \"i+5\"\n",
    "        RMSE_result.append(RMSE(modeledandmeasured_suffix[colnames[i+5]], modeledandmeasured_suffix[colnames[i]]))\n",
    "        MBD_abs_result.append(MBD_abs(modeledandmeasured_suffix[colnames[i+5]], modeledandmeasured_suffix[colnames[i]]))\n",
    "        RMSE_abs_result.append(RMSE_abs(modeledandmeasured_suffix[colnames[i+5]], modeledandmeasured_suffix[colnames[i]]))\n",
    "\n",
    "        modposition.append(colnames[i])\n",
    "        measposition.append(colnames[i+5])\n",
    "    except:\n",
    "        print(\" FAILED \", i, colnames[i])\n",
    "        faillist.append(colnames[i])\n",
    "\n",
    "# Join the arrays into a dataframe\n",
    "validationdf = pd.DataFrame(list(zip(modposition, measposition, MBD_result, RMSE_result, MBD_abs_result, RMSE_abs_result)), columns = ['Modeled', 'Measured', 'MBD', 'RMSE', 'MBD_abs', 'RMSE_abs'])    \n",
    "\n",
    "# Export the result into a csv\n",
    "validationdf.to_csv('out6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c22b464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea01baa-d860-4dd5-addd-874f5e208423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on a  Windows 10\n",
      "Python version  3.12.4 | packaged by Anaconda, Inc. | (main, Jun 18 2024, 15:03:56) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas version  2.2.2\n",
      "bifacialVF version  0.1.10.dev1+g107a777\n"
     ]
    }
   ],
   "source": [
    "# This information helps with debugging and getting support :)\n",
    "import sys, platform\n",
    "print(\"Working on a \", platform.system(), platform.release())\n",
    "print(\"Python version \", sys.version)\n",
    "print(\"Pandas version \", pd.__version__)\n",
    "print(\"bifacialVF version \", bifacialvf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ded0d035-2602-4134-a901-936becef09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "sazm = 180                  # PV Azimuth(deg) or tracker axis direction\n",
    "cw = 2 # m . 1-up portrait\n",
    "pitch=5.7\n",
    "hub_height=1.5 # m\n",
    "norm_hub_height = 1.5/cw\n",
    "norm_pitch = 5.7/cw\n",
    "rowType = \"interior\"        \n",
    "sensorsy = 12                # sampling areas in the module. edges would be 1 and 12.\n",
    "PVfrontSurface = \"glass\"    # options: glass or ARglass\n",
    "PVbackSurface = \"glass\"     # options: glass or ARglass\n",
    "\n",
    "# Tracking instructions\n",
    "tracking=True\n",
    "backtrack=True\n",
    "limit_angle = 52\n",
    "\n",
    "deltastyle = 'exact'  # NSRDB downloads data at center hour 11:30, 12:30, etc... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee16d5b8-4c3d-49f7-91c3-a7a2c7b86a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path = C:\\Users\\sayala\\Documents\\GitHub\\InSPIRE\\Studies\\BARN_Ground-Sensors\n",
      "Making path: EPWs\n",
      "Getting weather file: USA_VA_Richmond.724010_TMY2.epw\n",
      " ... OK!\n"
     ]
    }
   ],
   "source": [
    "#TMYtoread=bifacialvf.getEPW(lat=37.5407,lon=-77.4360)\n",
    "#myTMY3, meta = bifacialvf.readInputTMY(TMYtoread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b26fc87-8a0f-4007-89d0-9c8e9872a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherfile2 = r'C:\\Users\\sayala\\Documents\\GitHub\\InSPIRE\\Studies\\BARN_Ground-Sensors\\WeatherFiles\\PSM3_15T.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "963331db-0033-460a-a5e9-318a5f97d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = {'loc': 'LOCATION',\n",
    " 'city': 'Golden',\n",
    " 'state-prov': 'CO',\n",
    " 'country': 'USA',\n",
    " 'data_type': 'measured',\n",
    " 'latitude': 39.742,\n",
    " 'longitude': -105.179,\n",
    " 'TZ': -7.0,\n",
    " 'altitude': 1829.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22a19ec2-f095-4024-a4c1-b9863a36bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(weatherfile2, skiprows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5cdce299-447e-4c92-b35d-450b52753df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Tdry</th>\n",
       "      <th>DHI</th>\n",
       "      <th>DNI</th>\n",
       "      <th>GHI</th>\n",
       "      <th>Albedo</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-28 00:00:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>15.660000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-08-28 00:00:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-28 00:15:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.499933</td>\n",
       "      <td>15.588000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-08-28 00:15:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-28 00:30:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0.065467</td>\n",
       "      <td>15.507333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-08-28 00:30:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-28 00:45:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0.482867</td>\n",
       "      <td>15.386667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-08-28 00:45:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-28 01:00:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>15.268000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-08-28 01:00:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 23:00:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.587333</td>\n",
       "      <td>14.622000</td>\n",
       "      <td>0.127996</td>\n",
       "      <td>0.095033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-02 23:00:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 23:15:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>0.684933</td>\n",
       "      <td>13.648000</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.249243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-02 23:15:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 23:30:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>1.352067</td>\n",
       "      <td>14.110667</td>\n",
       "      <td>0.157131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-02 23:30:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-02 23:45:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>45</td>\n",
       "      <td>1.881000</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>0.118488</td>\n",
       "      <td>0.073451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-02 23:45:00-07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-03 00:00:00</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520286</td>\n",
       "      <td>13.876429</td>\n",
       "      <td>0.034872</td>\n",
       "      <td>0.078697</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-11-03 00:00:00-07:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6433 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Year  Month  Day  Hour  Minute      Wspd       Tdry  \\\n",
       "datetime                                                                   \n",
       "2023-08-28 00:00:00  2023      8   28     0       0  0.570000  15.660000   \n",
       "2023-08-28 00:15:00  2023      8   28     0      15  0.499933  15.588000   \n",
       "2023-08-28 00:30:00  2023      8   28     0      30  0.065467  15.507333   \n",
       "2023-08-28 00:45:00  2023      8   28     0      45  0.482867  15.386667   \n",
       "2023-08-28 01:00:00  2023      8   28     1       0  0.124200  15.268000   \n",
       "...                   ...    ...  ...   ...     ...       ...        ...   \n",
       "2023-11-02 23:00:00  2023     11    2    23       0  1.587333  14.622000   \n",
       "2023-11-02 23:15:00  2023     11    2    23      15  0.684933  13.648000   \n",
       "2023-11-02 23:30:00  2023     11    2    23      30  1.352067  14.110667   \n",
       "2023-11-02 23:45:00  2023     11    2    23      45  1.881000  14.320000   \n",
       "2023-11-03 00:00:00  2023     11    3     0       0  0.520286  13.876429   \n",
       "\n",
       "                          DHI       DNI  GHI  Albedo                  datetime  \n",
       "datetime                                                                        \n",
       "2023-08-28 00:00:00  0.000000  0.067881  0.0     0.0 2023-08-28 00:00:00-07:00  \n",
       "2023-08-28 00:15:00  0.000000  0.261778  0.0     0.0 2023-08-28 00:15:00-07:00  \n",
       "2023-08-28 00:30:00  0.000000  0.322695  0.0     0.0 2023-08-28 00:30:00-07:00  \n",
       "2023-08-28 00:45:00  0.000000  0.072407  0.0     0.0 2023-08-28 00:45:00-07:00  \n",
       "2023-08-28 01:00:00  0.000000  0.142377  0.0     0.0 2023-08-28 01:00:00-07:00  \n",
       "...                       ...       ...  ...     ...                       ...  \n",
       "2023-11-02 23:00:00  0.127996  0.095033  0.0     0.0 2023-11-02 23:00:00-07:00  \n",
       "2023-11-02 23:15:00  0.039862  0.249243  0.0     0.0 2023-11-02 23:15:00-07:00  \n",
       "2023-11-02 23:30:00  0.157131  0.000000  0.0     0.0 2023-11-02 23:30:00-07:00  \n",
       "2023-11-02 23:45:00  0.118488  0.073451  0.0     0.0 2023-11-02 23:45:00-07:00  \n",
       "2023-11-03 00:00:00  0.034872  0.078697  0.0     0.0 2023-11-03 00:00:00-07:00  \n",
       "\n",
       "[6433 rows x 12 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['datetime'] = pd.to_datetime(df[['Year', 'Month', 'Day', 'Hour', 'Minute']])\n",
    "df['datetime'] = df['datetime'].dt.tz_localize('Etc/GMT+7')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4be282f5-2ff5-4cf5-8586-69354b0c2dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c39fe33-e41f-4272-a246-8a10c5d2a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Sun position with no delta, for exact timestamp in input Weather File\n",
      "No albedo value set or included in TMY3 file (TMY Column name 'Alb (unitless)' expected) Setting albedo default to 0.2\n",
      " \n",
      " \n",
      "********* \n",
      "Running Simulation for TMY3: \n",
      "Location:   Golden\n",
      "Lat:  39.742  Long:  -105.179  Tz  -7.0\n",
      "Parameters: tilt:  0   Sazm:  180     Hub_Height :  0.75   Pitch:  2.85   Row type:  interior   Albedo:  0.2\n",
      "Saving into bifacial_VF_ground.csv\n",
      " \n",
      " \n",
      "Distance between rows for no shading on Dec 21 at 9 am solar time =  0.0\n",
      "Actual distance between rows =  1.85\n",
      " \n",
      " ***** IMPORTANT --> THIS SIMULATION Has Tracking Activated\n",
      "Backtracking Option is set to:  True\n",
      "Saving Ground Irradiance Values for AgriPV Analysis. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6433/6433 [00:28<00:00, 226.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writefiletitle = os.path.join('bifacial_VF_ground.csv')\n",
    "bifacialvf.simulate(df, meta, writefiletitle=writefiletitle, \n",
    "            sazm=sazm, pitch=norm_pitch, hub_height=norm_hub_height, \n",
    "         rowType=rowType, sensorsy=sensorsy, \n",
    "         PVfrontSurface=PVfrontSurface, PVbackSurface=PVbackSurface, \n",
    "          tracking=tracking, backtrack=backtrack, agriPV=True,\n",
    "         limit_angle=limit_angle, deltastyle=deltastyle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b29a4ee-44fb-45a4-8c60-cd675bbb4712",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
